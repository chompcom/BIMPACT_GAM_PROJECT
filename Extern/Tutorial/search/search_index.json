{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Introduction","text":"<p>Alpha Engine is a C library that facilitates creating an application on Windows. It provides functions for input, graphics rendering, window management and audio. </p> <p>This document contains step-by-step guides to get users started and use Alpha Engine.</p>"},{"location":"index.html#prerequisites","title":"Prerequisites","text":"<p>This document assume that the students that familiar with the following concepts and tools:</p> <ul> <li>Transformation matrices and column-major matrix concatenation (multiplication).</li> <li>Programming in C.</li> <li>Using Visual Studios 2022 to build and run an application in Windows.</li> <li>Basic understanding of game loops, sprite animations, global/local spaces, input handling, and rendering.</li> </ul> <p>To follow along with the tutorial, you need to download the assets we will use and code snippets for further references.</p>"},{"location":"camera_system.html","title":"Camera System","text":""},{"location":"camera_system.html#basics-of-camera-movement","title":"Basics of camera movement","text":"<p>In computer graphics, the idea of a \"camera\" is simply a matrix that is applied on top of the transform that you set before rendering a mesh.  In this section, we are go through the basics of implementing a \"camera\".</p> <p>It illustrate this, let's use our previous sprite rendering example. </p> <p>When we calculated its transformation matrix, we formed the matrix transformation of our sprite using TRS:</p> \\[ T_{sprite} = \\begin{bmatrix} 1 &amp; 0 &amp; t_x \\\\ 0 &amp; 1 &amp; t_y \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\begin{bmatrix} \\cos(r) &amp; -\\sin(r) &amp; 0 \\\\ \\sin(r) &amp; \\cos(r) &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\begin{bmatrix} s_x &amp; 0 &amp; 0 \\\\ 0 &amp; s_y &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\] <p>In computer graphics, we don't have a \"camera\" object per se.  What we have are transforms to concatenate together for each sprite. We can use this to simulate the effect of a \"camera\".</p> <p>Let's start with camera movement. If we wanted to \"move our camera to the right\", what we will essentially be doing is to move our sprites to the left. Likewise, if we wanted to \"move our camera upwards\", we will move our sprites downwards.  Essentially, we will translate our sprites the negative of the camera's position.</p> <p>As an example, if our sprite is at <code>x = 100</code> and our \"camera\" is at <code>x = 100</code>, what we should see is that our sprite is rendered as if it's at <code>x = 0</code>.</p> <p>We do this for every sprite that we want to be affected by our so-called \"camera\".</p> <p>Therefore, the idea of a implementing camera movement is simply to concatenate our sprite's transform with a translation matrix that moves our object by the negative camera position. </p> \\[ T_{sprite} = \\begin{bmatrix} 1 &amp; 0 &amp; -c_x \\\\ 0 &amp; 1 &amp; -c_y \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\begin{bmatrix} 1 &amp; 0 &amp; t_x \\\\ 0 &amp; 1 &amp; t_y \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\begin{bmatrix} \\cos(r) &amp; -\\sin(r) &amp; 0 \\\\ \\sin(r) &amp; \\cos(r) &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\begin{bmatrix} s_x &amp; 0 &amp; 0 \\\\ 0 &amp; s_y &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\] <p>where \\(c_x\\) is the camera's X position and \\(c_y\\) is the camera's Y position.</p>"},{"location":"camera_system.html#camera-movement-with-alpha-engine","title":"Camera movement with Alpha Engine","text":"<p>Alpha Engine provides a few functions that will simulate camera movements all meshes drawn by <code>AEGfxMeshDraw()</code>:</p> <ul> <li>AEGfxSetCamPosition()</li> <li>AEGfxGetCamPosition().</li> </ul>"},{"location":"camera_system.html#exercise","title":"Exercise","text":"<p>Try to write your own camera movement system without using Alpha Engine's camera functions! Can you come up with a camera system that does zooms and rotations?</p>"},{"location":"coordinate_systems.html","title":"Coordinate Systems","text":"<p>When programming an application, we work with multiple coordinate systems. For example, when we render 2D images on the screen, we might use pixel coordinates to describe the sizes and positions of the images.  However, when we create a user interface (UI), we may use percentages to describe a UI element's size and position on the screen in order to cater for multiple screen sizes.</p> <p>Therefore, it is important to be aware of the difference spaces you have to work and, when needed, convert between them.</p> <p>Depending on the complexity of your application, you can have as few as 1 coordinate system to as many as you need. In Alpha Engine, there are 3 coordinate systems used. They are: World Coordinates, Screen Coordinates, Normalized Screen Coordinates.</p>"},{"location":"coordinate_systems.html#world-coordinates","title":"World Coordinates","text":"<p>Alpha Engine uses the World Coordinates to render the instances of your meshes. It has the following attributes:</p> <ul> <li>The origin is in the middle.</li> <li>The x-axis goes horizontally towards the right.</li> <li>The y-axis goes vertically upwards. </li> <li>For both axes, each unit is 1 pixel wide. </li> </ul> <p>Assuming a 1600x900 resolution, it follows the diagram below:</p> <p></p> <p>For more information on how to render a mesh in World Coordinates, check out the sprite rendering section. </p>"},{"location":"coordinate_systems.html#screen-coordinates","title":"Screen Coordinates","text":"<p>Alpha Engine uses Screen Coordinates for elements that that live on the monitor, in terms of monitor pixels. A function that uses Screen Coordiniates is <code>AEInputGetCursorPosition()</code>, which gets the mouse cursor's position on the monitor. It has the following attributes:</p> <ul> <li>The origin is in the top left hand corner of the renderable area of your application window. </li> <li>The x-axis goes horizontally towards the right.</li> <li>The y-axis goes vertically downwards.</li> <li>For both axes, each unit is 1 pixel wide. </li> </ul> <p>Warning</p> <p>Since a monitor is made up of concrete pixels, there is no such thing as a half-pixel position. For example, there is no such thing as a mouse position at x = 1.5.</p> <p>Assuming a 1600x900 resolution, it follows the diagram below:</p> <p></p>"},{"location":"coordinate_systems.html#normalized-coordinates","title":"Normalized Coordinates","text":"<p>Alpha Engine uses Normalized Coordinates for rendering text. The Normalized Coordinates describes the application window in terms of percentage. It has the following attributes:</p> <ul> <li>The origin is at the middle of the screen.</li> <li>The x-axis goes horizontally towards the right, with 1.0 being the rightmost side of the window and -1.0 being the leftmost side of the window.</li> <li>The y-axis goes vertically upwards, with 1.0 being the top of the screen and -1.0 being the bottom of the screen.</li> </ul> <p></p> <p>Note</p> <p>Normalized coordinates can be useful for describing position and size of an element because its values are not dependant on the screen resolution. This means that x = 1.0 always describes that right side of the window, whether the window is in 800x600, 1600x900 or 1920x1080 resolution.</p>"},{"location":"input.html","title":"Input Handling","text":"<p>Alpha Engine only supports mouse and keyboard input. It does not support input from other sources (e.g. controllers).</p>"},{"location":"input.html#mouse-position","title":"Mouse Position","text":"<p>Getting the current mouse cursor position is straightforward with <code>AEInputGetCursorPosition()</code>:</p> <pre><code>s32 x, y;\nAEInputGetCursorPosition(&amp;x, &amp;y);\n// After the previous line, x should contain the x-position of the cursor\n// while y will contain the y-position of the cursor.\n</code></pre> <p>Warning</p> <p>Note that the mouse cursor position obtained via <code>AEInputGetCursorPosition()</code> is in Screen Coordinates. Screen Coordinates are detailed here: &lt;&gt;."},{"location":"input.html#key-presses","title":"Key Presses","text":"<p>When it comes to key input (via mouse buttons or keyboard keys), pay close attention to how a key is being pressed.  The OS can only tell us whether a key is pressed or released.  Alpha Engine takes a step further by recording whether a key is pressed/released the previous frame. For common cases, the following functions might be good enough for your application:</p> <ul> <li><code>AEInputCheckTriggered()</code>: This checks if a key is just pressed.</li> <li><code>AEInputCheckReleased()</code>: This checks if a key is just released.</li> </ul> <p>For example:</p> <pre><code>// Checks if escape key is recently pressed.\nif (AEInputCheckTriggered(AEVK_ESCAPE)) { ... }\n\n// Checks if escape key is recently released.\nif (AEInputCheckRelease(AEVK_ESCAPE)) { ... }\n</code></pre> <p>For more information related to input, check out the documentation surrounding the <code>AEInput.h</code> file.</p>"},{"location":"playing_audio.html","title":"Playing Audio","text":""},{"location":"playing_audio.html#differences-between-sound-and-music","title":"Differences between Sound and Music","text":"<p>Alpha Engine supports loading of multiple types of audio files including <code>.mp3</code> and <code>.wav</code> formats. </p> <p>In Alpha Engine, audio is separated into 2 types: <code>Sound</code> and <code>Music</code>. </p> <p><code>Sounds</code> are audios that are fully loaded into the memory before being played.  They are most suitable to short sound effects that are played repeatedly.  To load a Sound-type audio, simply use this function:</p> <pre><code>// Loads a sound from given filepath and assign to 'audio'\nAEAudio audio = AEAudioLoadSound(\"filepath\");\n</code></pre> <p><code>Music</code> are audios that are streamed from file.  This means that they are loaded as separate chunks into the memory as it is being played.  For example, the first 10 seconds of a music is first loaded into memory. Before the 10 seconds is done playing, the next 10 seconds is loaded.  This repeats until the music is done. </p> <p>To load a Music-type audio, simply use this function:</p> <pre><code>// Loads a music from given filepath and assign it to 'audio'\nAEAudio audio = AEAudioLoadMusic(\"filepath\");\n</code></pre> <p>One noticable difference between <code>Sound</code> and <code>Music</code> is that multiple <code>Sound</code> from the same  <code>AEAudio</code> can overlap each other when you play them (up to a certain amount, of course).  Multiple <code>Music</code> from the same <code>AEAudio</code>, however, cannot overlap each other. </p> <p>That is, if you use <code>AEAudioPlay</code> on multiple <code>Sounds</code> from the same <code>AEAudio</code> at once, you will hear multiple <code>Sounds</code> being played.  If you use <code>AEAudioPlay</code> on multiple <code>Music</code> at once, only the last <code>Music</code> will be played; the previous </p>"},{"location":"playing_audio.html#playing-an-audio","title":"Playing an Audio","text":"<p><code>AEAudio</code> is a type that represents an audio (which can either be a <code>Sound</code> or <code>Music</code>) loaded by Alpha Engine.  Before we can play an audio, we must first create an audio group for the audio to play in. </p> <p>You can create an audio group simply with the following function:</p> <pre><code>// Creates an audio group\nAEAudioGroup audio_group = AEAudioCreateGroup();\n</code></pre> <p><code>AEAudioGroup</code> is a type that represents an audio group where <code>AEAudios</code> are played in.  Typically, we would create one <code>AEAudioGroup</code> for background music and another audio group for sound effects. </p> <p>To play an audio, we simply use <code>AEAudioPlay</code>. </p> <p>As an example, we will load a sound from a file named \"ore.mp3\" in the Assets folder and play it at the start of the application. Write the code below before entering the game loop:</p> <pre><code>// Loads a sound from a file named 'ore.mp3' in the 'Assets' folder \n// and assign it to 'ore'\nAEAudio ore = AEAudioLoadSound(\"Assets/ore.mp3\");\n\n// Creates an audio group named 'sound_effect'\nAEAudioGroup sound_effect = AEAudioCreateGroup();\n\n// Plays 'ore' audio in the \"sound_effect\" audio group with \n// 100% volume, 100% pitch, looped infinitely.\nAEAudioPlay(ore, sound_effect, 1.f, 1.f, -1);\n</code></pre> <p>Upon compiling and running the application, you should be able to hear a sound.</p> <p>Next, we will load a background music to play.  This time, we will lower the volume and increase the pitch of the music. Note that we are now using <code>AEAudioLoadMusic</code> instead! Write the code below before entering the game loop:</p> <pre><code>// Loads a sound from a file named 'bouken.mp3' in the 'Assets' folder \n// and assign it to 'bouken'.\nAEAudio bouken = AEAudioLoadMusic(\"Assets/bouken.mp3\");\n\n// Creates an audio group named 'bgm'\nAEAudioGroup bgm = AEAudioCreateGroup();\n\n// Plays 'bouken' audio in the \"bgm\" audio group with \n// 50% volume, 200% pitch, looped infinitely.\nAEAudioPlay(bouken, bgm, 0.5f, 2.f, -1);\n</code></pre> <p>When you run the application this time, you should be able to hear a soft music playing in the background in a very fast pace.  Try to play \"bouken.mp3\" in your preferred music player and compare the differences!</p>"},{"location":"playing_audio.html#releasing-resources","title":"Releasing resources","text":"<p>Finally, we will need to clean up the AEAudioGroups and AEAudios that we created. <code>AEUnloadAudio</code> will free the resources used by a <code>AEAudio</code> object. <code>AEUnloadAudioGroup</code> will free the resources used by a <code>AEAudioGroup</code> object. Thus, before exiting the application, we will write the following code to clean our audio up:</p> <pre><code>// Release our audios.\nAEUnloadAudio(bouken);\nAEUnloadAudio(ore)\n\n// Release our audio groups.\nAEUnloadAudioGroup(sound_effect);\nAEUnloadAudioGroup(bgm);\n</code></pre>"},{"location":"playing_audio.html#sample-code","title":"Sample code","text":"<p>Sample code regarding audio can be found in <code>snippets\\playing_audio.cpp</code>. For more information related to audio, check out the documentation surrounding the <code>AEAudio.h</code> file.</p>"},{"location":"primitive_types.html","title":"Primitive Types","text":"<p>In Alpha Engine, some primitivate types have been renamed to contain more information about the amount of bits and bytes we want our variables to occupy.</p> <pre><code>#include &lt;cstdint&gt;\ntypedef int8_t    s8;\ntypedef uint8_t   u8;\ntypedef int16_t   s16;\ntypedef uint16_t  u16;\ntypedef int32_t   s32;\ntypedef uint32_t  u32;\ntypedef int64_t   s64;\ntypedef uint64_t  u64;\ntypedef float     f32;\ntypedef double    f64;\n</code></pre> <p><code>u8</code> stands for 'unsigned 8 bits'. <code>s8</code> stands for 'signed 8 bits'.  <code>u16</code> then obviously stands for 'unsigned 16 bits', so on and so forth. <code>f32</code> stands for '32-bit floating point' and <code>f64</code> stands for '64-bit floating point'. </p> <p>This technique is common in modern programming. </p> <p>You might ask, why not use the primitive types as is? Like <code>int</code> or <code>short</code>?</p> <p>Doing it this way is not only clearer, but it also eliminates the need to change your primitive types based on different computer achitectures.</p> <p>Consider that we declare a simple <code>int</code> like so:</p> <pre><code>int i = 0; // How many bytes is i?\n</code></pre> <p>We might assume that an <code>int</code> is 4 bytes. However, the reality is that this might not always be true. Notice that in your programming class, quizzes always allow you to assume that <code>int</code> is 4 bytes!</p> <p>The reality is that what <code>int</code> is depends on the compiler, which in turn depends on your computer architecture. This is stated in C++'s specifications:</p> <p>int - basic integer type. The keyword int may be omitted if any of the modifiers listed below are used. If no length modifiers are present, it's guaranteed to have a width of at least 16 bits. However, on 32/64 bit systems it is almost exclusively guaranteed to have width of at least 32 bits (see below).  - cppreference</p> <p>Thankfully since C99, compilers need to implement the header file  which provides typedefs that allows programmers to specify exactly how many bytes they want their variable to occupy (amongst other things). Alpha Engine simply takes the typedefs it needs from that header file and shortened them."},{"location":"project_setup.html","title":"Project Setup","text":"<p>In this section, we will cover how to create a new Visual Studios 2022 project in Alpha Engine. </p> <p>Be sure to download Assets here and the Alpha Engine library on Moodle before continuing.</p>"},{"location":"project_setup.html#project-creation","title":"Project Creation","text":"<p>First, we will create the Visual Studios Solution and Project files that will be used to run our first application.</p> <ul> <li>Open Visual Studios. You should see a window that looks like this:</li> </ul> <p></p> <ul> <li>Under the <code>Visual Studio 2022</code> window:<ul> <li>Click on <code>Create a new project</code></li> </ul> </li> <li>Under the <code>Create a new project</code> window:<ul> <li>Click on <code>Empty Project</code>. Make sure that it's the C++ version. </li> <li>Click on <code>Next</code>.</li> </ul> </li> <li>Under the <code>Configure your new project</code> page:<ul> <li>(Optional) Change the <code>Project Name</code> to one of your liking.</li> <li>(Optional) Change the Location.</li> <li>Uncheck <code>Place solution and project in the same directory</code>.</li> <li>Note the Location as we need to navigate to it later.</li> <li>Click on <code>Create</code>.</li> </ul> </li> </ul> <p>You should see Visual Studios appear on your screen, like so:</p> <p></p> <p>This means that it has successfully created and opened.</p> <p>In this project, we will not be building for 32-bit systems, so to avoid confusion, we need to remove 32-bit system-related configurations from the project.</p> <ul> <li>Under <code>Build</code> &gt; <code>Configuration Manager</code> <ul> <li>Click on <code>Active Solution Platform</code> &gt; <code>Edit\u2026</code> &gt; Click on <code>x86</code> &gt; <code>Remove</code></li> <li>Click on <code>Platform</code> &gt; <code>Edit\u2026</code> &gt; Click on <code>Win32</code> &gt; <code>Remove</code></li> </ul> </li> </ul>"},{"location":"project_setup.html#adding-a-folder-for-alpha-engine-and-assets","title":"Adding a folder for Alpha Engine and assets","text":"<p>Next, we will add the Alpha Engine library to a location within the project folder.  This is so that our project can easily locate Alpha Engine\u2019s header and library files, and subsequently use its code.</p> <ul> <li>Go to the project\u2019s Solution File (.sln) using Windows Explorer. It should be at the Location that you set earlier.</li> <li>Create a folder named <code>Extern</code> at that location.</li> <li>Create a folder named <code>Assets</code> at that location.</li> <li>Copy the AlphaEngine folder in the given AlphaEngine.zip file into the <code>Extern</code> folder.</li> <li>Copy the contents in the given <code>Assets.zip</code> file into the <code>Assets</code> folder.</li> </ul>"},{"location":"project_setup.html#project-configuration","title":"Project Configuration","text":"<p>Next, we configure the project properties. Right-click on the project in the Solution Explorer:</p> <p></p> <p>Then click on <code>Properties</code>.  It should open a window that looks something like this:</p> <p></p> <p>This window contains all configurations of the project. By default, all projects in VS2022 come with two configurations to compile the app: <code>Debug</code> and <code>Release</code>.</p> <p>In general, <code>Debug</code> builds are easier to debug but slower. <code>Release</code> builds are most optimized but are harder to debug.</p> <p>Set the <code>Configuration</code> drop down bar to <code>All Configurations</code>. This will cause our settings to affect both <code>Debug</code> and <code>Release</code> versions of our application. </p> <p></p> <p>Add the additional directories the compiler needs to look for when compiling and linking:</p> <ul> <li>Under <code>Configuration Properties</code> &gt; <code>VC++ Directories</code><ul> <li>Add <code>$(SolutionDir)Extern\\AlphaEngine\\include</code> to <code>General</code> &gt; <code>Include Directories</code></li> <li>Add <code>$(SolutionDir)Extern\\AlphaEngine\\lib</code> to <code>General</code> &gt; <code>Library Directories</code></li> </ul> </li> </ul> <p>Warning</p> <p>When you add an entry into a section, you have to seperate each entry with ';'. For example, if the entry for <code>Include Directories</code> is: <code>$(VC_IncludePath);$(WindowsSDK_IncludePath)</code>, to add <code>$(SolutionDir)Extern\\CProcessing\\include</code>, you will have to do: <code>$(VC_IncludePath);$(WindowsSDK_IncludePath);$(SolutionDir)Extern\\CProcessing\\include</code></p> <p>Configure the character set the project is using.</p> <ul> <li>Under <code>Configuration Properties</code> &gt; <code>Advanced</code> &gt; <code>Character Set</code><ul> <li>Set to <code>Use Multibyte Set</code></li> </ul> </li> </ul> <p>Configure the subsystem the project is using.</p> <ul> <li>Under <code>Configuration Properties</code> &gt; <code>Linker</code> &gt; <code>System</code> &gt; <code>Subsystem</code><ul> <li>Set to <code>Windows (/SUBSYSTEM:WINDOWS)</code></li> </ul> </li> </ul> <p>Set the output directory of the compiler where the executable will be created.  We will set this to a folder named <code>bin</code> at the directory the Solution file is in:</p> <ul> <li>Under <code>Configuration Properties</code> &gt; <code>General</code> &gt; <code>Output Directory</code><ul> <li>Set to <code>$(SolutionDir)bin\\$(Configuration)-$(Platform)\\</code></li> </ul> </li> </ul> <p>Set the intermediate directory of the compiler.  This is where all the 'rubbish' files that the compiler generates will go to. We will set this to a folder named \".tmp\" at the directory the Solution file is in:</p> <ul> <li>Under <code>Configuration Properties</code> &gt; <code>General</code> &gt; <code>Intermediate Directory</code><ul> <li>Set to <code>$(SolutionDir).tmp\\$(Configuration)-$(Platform)\\</code></li> </ul> </li> </ul> <p>Set the working directory of the debugger to be in the same directory as the executables output by the compiler:</p> <ul> <li>Under <code>Configuration Properties</code> &gt; <code>Debugging</code>  &gt; <code>Working Directory</code><ul> <li>Set to <code>$(SolutionDir)bin\\$(Configuration)-$(Platform)\\</code></li> </ul> </li> </ul> <p>Warning</p> <p>For the next few steps, you might need to change the <code>Configuration</code> drop down to either <code>Debug</code> to <code>Release</code>. Follow the steps carefully!</p> <p>Configure the linker to link to the appropriate Alpha Engine depending on whether we are on Debug or Release configurations:</p> <ul> <li>Click on <code>Configuration Properties</code> &gt; <code>Linker</code> &gt; <code>Input</code> &gt; <code>Additional Dependencies</code><ul> <li>With <code>Configuration</code> set to <code>Debug</code>:<ul> <li>Click on the <code>v</code> arrow at the right side of the text field to toggle a dropdown menu</li> <li>Click on <code>&lt;Edit...&gt;</code>. A window should appear.</li> <li>Add <code>Alpha_EngineD.lib</code>. </li> <li>Click on <code>OK</code> to close the window.</li> <li>Click on <code>Apply</code></li> </ul> </li> <li>With <code>Configuration</code> set to <code>Release</code><ul> <li>Click on the <code>v</code> arrow at the right side of the text field to toggle a dropdown menu</li> <li>Click on <code>&lt;Edit...&gt;</code>. A window should appear.</li> <li>Add <code>Alpha_Engine.lib</code></li> <li>Click on <code>OK</code> to close the window.</li> <li>Click on <code>Apply</code></li> </ul> </li> </ul> </li> </ul> <p>Tell Visual Studios to copy the appropriate .dll and assets to where the executable is after it's built:</p> <ul> <li>Under <code>Configuration Properties</code> &gt; <code>Build Events</code> &gt; <code>Post-Build Event</code> &gt; <code>Command Line</code> &gt; <code>Edit\u2026</code><ul> <li>With <code>Configuration</code> set to <code>Debug</code>:<ul> <li>Click on the <code>v</code> arrow at the right side of the text field to toggle a dropdown menu</li> <li>Click on <code>&lt;Edit...&gt;</code>. A window should appear.</li> <li>Add <code>xcopy \"$(SolutionDir)Assets\\</code>\" \"$(OutDir)Assets\\\" /s /r /y /q`</li> <li>Add <code>xcopy \"$(SolutionDir)Extern\\AlphaEngine\\lib\\freetype.dll\" \"$(OutDir)\" /s /r /y /q</code></li> <li>Add <code>xcopy \"$(SolutionDir)Extern\\AlphaEngine\\lib\\Alpha_EngineD.dll\" \"$(OutDir)\" /s /r /y /q</code></li> <li>Add <code>xcopy \"$(SolutionDir)Extern\\AlphaEngine\\lib\\fmodL.dll\" \"$(OutDir)\" /s /r /y /q</code></li> <li>Click on <code>OK</code> to close the window.</li> <li>Click on <code>Apply</code></li> </ul> </li> <li>With <code>Configuration</code> set to <code>Release</code>:<ul> <li>Click on the <code>v</code> arrow at the right side of the text field to toggle a dropdown menu</li> <li>Click on <code>&lt;Edit...&gt;</code>. A window should appear.</li> <li>Add <code>xcopy \"$(SolutionDir)Assets\\</code>\" \"$(OutDir)Assets\\\" /s /r /y /q`</li> <li>Add <code>xcopy \"$(SolutionDir)Extern\\AlphaEngine\\lib\\freetype.dll\" \"$(OutDir)\" /s /r /y /q</code></li> <li>Add <code>xcopy \"$(SolutionDir)Extern\\AlphaEngine\\lib\\Alpha_Engine.dll\" \"$(OutDir)\" /s /r /y /q</code></li> <li>Add <code>xcopy \"$(SolutionDir)Extern\\AlphaEngine\\lib\\fmod.dll\" \"$(OutDir)\" /s /r /y /q</code></li> <li>Click on <code>OK</code> to close the window.</li> <li>Click on <code>Apply</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"project_setup.html#running-our-first-application","title":"Running our first application","text":"<p>Create a fresh CPP file with the entry point function and name it <code>Main.cpp</code>.</p> <ul> <li>Open File Explorer and navigate to the project's directory.</li> <li>Create a folder there to hold all our code. For this example, we will name the folder <code>Source</code></li> <li>Go into the <code>Source</code> folder and create a file named <code>Main.cpp</code>. This will contain the code with the entry point to our application.</li> <li>Drag and drop <code>Main.cpp</code> from the File Explorer into the Source File filter in Visual Studios 2022.</li> </ul> <p></p> <ul> <li>Copy the code from the given <code>snippets\\barebones.cpp</code> into the <code>Main.cpp</code> file that you just created.</li> <li>Build and run the project.</li> <li>You should see a blank window with the title \"My New Demo\" pop up with a console window at the back. The problem should close upon pressing the escape key.</li> </ul> <p>If you got here, congratulations! You have set up Alpha Engine!</p> <p>Note</p> <p>If you are new to Visual Studios, it is recommended to follow these steps to add a new source file into Visual Studios. This will at least keep our source files organized into a folder, rather than all over the project. If you have a better idea on how you want to organize your source files, feel free to do so!</p>"},{"location":"rendering_sprites.html","title":"Rendering A Sprite","text":"<p>In this section, we will cover the basics of rendering something on the screen with Alpha Engine.  In Alpha Engine, rendering something on the screen goes through similar steps as rendering something using a graphics API like OpenGL, DirectX and Vulkan.  Alpha Engine simplifies the steps so that you don\u2019t have to manage the underlying details.</p> <p>The steps are generally as follows:</p> <ul> <li>Create a Mesh (sometimes called a Model) on initialization. A Mesh is just a collection of triangles, which are a collection of 3 vertices.  You can of a Mesh as a blueprint, which we can create clones of to draw on the screen. </li> <li>In the game loop:<ul> <li>Set various settings in Alpha Engine to tell it how you want to draw the Mesh. For example:<ul> <li>What transform to apply to all vertices of the mesh.</li> <li>What texture to apply onto the mesh.</li> <li>...and more!</li> </ul> </li> <li>Inform Alpha Engine to draw a mesh based on the settings provided in the previous step.</li> </ul> </li> </ul> <p>In the following sections, we detail the steps to render a few simple sprites.  A sprite in computer graphics is a 2 dimensional image that is rendered somewhere within our window. </p>"},{"location":"rendering_sprites.html#creating-a-1x1-mesh","title":"Creating a 1x1 mesh","text":"<p>For most implementation of sprites, you can get away with a single 1x1 white square mesh that is centered around the origin.</p> <p></p> <p>In modern graphics implementations, our meshes are made up of triangles.  A square mesh can be made out of 2 triangles. A triangle is made up of 3 vertices. There are a few ways to arrange two triangles to form a square but we will use these values for this example:</p> \\[ \\triangle A = \\begin{bmatrix} -0.5 \\\\ -0.5 \\end{bmatrix}, \\begin{bmatrix} -0.5 \\\\ 0.5 \\end{bmatrix}, \\begin{bmatrix} 0.5 \\\\ -0.5 \\end{bmatrix} \\] \\[ \\triangle B = \\begin{bmatrix} 0.5 \\\\ -0.5 \\end{bmatrix}, \\begin{bmatrix} 0.5 \\\\ 0.5 \\end{bmatrix}, \\begin{bmatrix} -0.5 \\\\ 0.5 \\end{bmatrix} \\] <p></p> <p>XY coordinates are not the only things that a vertex can store. In theory, a vertex store as many addiional information you want! In Alpha Engine, a vertex can store the following information:</p> <ul> <li>XY Coordinates </li> <li>Color</li> <li>UV Coordinates</li> </ul> <p>Color is irrelevant for this section, so we will ignore it for now. It will be covered in a later section.</p> <p>The next thing we need to talk about is UV Coordinates.</p> <p>UV coordinates are coordinates of an image, which are rectangular in nature.  In Alpha Engine, U represents the X-axis of an image going from left to right, while V represents the Y axis of an image going from top to bottom.  The origin is at the top-left hand portion of the image. Both U and V values range from 0.0 to 1.0.  This means that the bottom-right of an image has the coordinates U = 1.0 and V = 1.0. </p> <p></p> <p>To ensure that our renderer applies the image onto our mesh correctly, we need to map the correct UV coordinates to each vertex of our mesh. </p> <p>Given that the XY coordinates of each of our vertices represents a corner, we simple map a UV coordinate that corresponds to that corner of the image to the vertex. </p> <p>This means that we will map the vertex that represents the top-left corner of our mesh to the UV coordinate that represents the top-left of the image, the bottom-right vertex to the UV coordinates that represents the bottom-right of the image, and so on.</p> <p>The code below will create a square mesh of 1 pixel width and height centered around the origin and store it under <code>pMesh</code>.  Do this BEFORE the game loop. </p> <p>Warning</p> <p>Do not create a mesh within the game loop! We don't want to create a mesh each frame!</p> <pre><code>// We inform Alpha Engine that we are going to create a mesh\nAEGfxMeshStart();\n\n// AEGfxTriAdd() takes in 3 sets of 5 parameters,\n// totalling to a whooping 15 parameters to input.\n//\n// Each set represents a vertex, and with three sets\n// we form a single triangle. \n// \n// The 5 parameters in a set are:\n// - A vertex's x value\n// - A vertex's y value\n// - A vertex's color in hexadecimal\n// - The U value of a texture to map to this vertex\n// - The V value of a texture to map to this vertex\n\n// The code below tells Alpha Engine that the mesh will contain 2 \n// triangles that makes up a white square. \n//\n// Notice that this 1x1 white square is centered around the origin.\n//\n\nAEGfxTriAdd(\n  -0.5f, -0.5f, 0xFFFFFFFF, 0.0f, 1.0f,\n  0.5f, -0.5f, 0xFFFFFFFF, 1.0f, 1.0f,\n  -0.5f, 0.5f, 0xFFFFFFFF, 0.0f, 0.0f);\n\nAEGfxTriAdd(\n  0.5f, -0.5f, 0xFFFFFFFF, 1.0f, 1.0f,\n  0.5f, 0.5f, 0xFFFFFFFF, 1.0f, 0.0f,\n  -0.5f, 0.5f, 0xFFFFFFFF, 0.0f, 0.0f);\n\n// Saving the mesh (list of triangles) in pMesh\nAEGfxVertexList * pMesh = AEGfxMeshEnd();\n</code></pre> <p>After you are done with the Mesh, remember to free it AFTER the game loop BEFORE the application exits with:</p> <pre><code>// This will free the Mesh.\nAEGfxMeshFree(pMesh);\n</code></pre>"},{"location":"rendering_sprites.html#loading-a-texture","title":"Loading A Texture","text":"<p>Loading a texture is straightforward.  The code below will load a texture located in our Assets folder and store it under <code>pTex</code>:</p> <pre><code>// This will load a texture in `Assets/PlanetTexture.png` \n// and store it in pTex. \nAEGfxTexture* pTex = AEGfxTextureLoad(\"Assets/PlanetTexture.png\");\n</code></pre> <p>After you are done with the Texture, remember to free it AFTER the game loop BEFORE the application exits:</p> <pre><code>// 'Frees' the texture.\nAEGfxTextureUnload(pTex);\n</code></pre>"},{"location":"rendering_sprites.html#calculating-the-transformation-matrix","title":"Calculating the transformation matrix","text":"<p>Our next step is to calculate a transformation matrix that will be applied to every vertex of our mesh.  In our example, let's say we want a sprite that is:</p> <ul> <li>Scaled 500 pixels width and height </li> <li>Rotated by 90 degrees anti-clockwise</li> <li>Translated 200 pixels along the x-axis and 100 along the y-axis</li> </ul> <p>To calculate the transformation matrix \\(F\\) for this, it's a simple case of concatenating the scale, rotation and translation matrices in that order.</p> \\[ F = \\begin{bmatrix} 1 &amp; 0 &amp; t_x \\\\ 0 &amp; 1 &amp; t_y \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\begin{bmatrix} \\cos(r) &amp; -\\sin(r) &amp; 0 \\\\ \\sin(r) &amp; \\cos(r) &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\begin{bmatrix} s_x &amp; 0 &amp; 0 \\\\ 0 &amp; s_y &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\] <p>Where:</p> <ul> <li>\\(t_x, t_y\\) represents our translation along the x and y axis respectively.</li> <li>\\(s_x, s_y\\) represents our scale along the x and y axis respectively.</li> <li>\\(r\\) represents the angle of anticlockwise rotation in radians. </li> </ul> <p>Thus, substituting the values we want in, we should get the following matrices:</p> \\[ F = \\begin{bmatrix} 1 &amp; 0 &amp; 200 \\\\ 0 &amp; 1 &amp; 100 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\begin{bmatrix} \\cos(\\frac{\\pi}{2}) &amp; \\sin(\\frac{\\pi}{2}) &amp; 0 \\\\ \\sin(\\frac{\\pi}{2}) &amp; \\cos(\\frac{\\pi}{2}) &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\begin{bmatrix} 500 &amp; 0 &amp; 0 \\\\ 0 &amp; 500 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\] <p>Now that we know how to form our transformation matrix, we need to translate that into code.  Below is a snippet on how to do it in Alpha Engine.</p> <pre><code>// Create a scale matrix that scales by 500 x and y\nAEMtx33 scale = { 0 };\nAEMtx33Scale(&amp;scale, 500.f, 500.f);\n\n// Create a rotation matrix that rotates by 90 degrees\n// Note that PI in radians is 180 degrees.\n// Since 90 degrees is 180/2, 90 degrees in radians is PI/2\nAEMtx33 rotate = { 0 };\nAEMtx33Rot(&amp;rotate, PI/2);\n\n// Create a translation matrix that translates by\n// 200 in the x-axis and 100 in the y-axis\nAEMtx33 translate = { 0 };\nAEMtx33Trans(&amp;translate, 200.f, 100.f);\n\n// Concatenate the matrices into the 'transform' variable.\n// We concatenate in the order of translation * rotation * scale\n// i.e. this means we scale, then rotate, then translate.\nAEMtx33 transform = { 0 };\nAEMtx33Concat(&amp;transform, &amp;rotate, &amp;scale);\nAEMtx33Concat(&amp;transform, &amp;translate, &amp;transform);\n</code></pre> <p>Note that this is just a way to put together a transformation matrix that will be used to render a sprite in our example. Alpha Engine doesn't care about how you form the transformation matrix; it just uses the final matrix you give it. </p>"},{"location":"rendering_sprites.html#putting-it-all-together-to-render-a-sprite","title":"Putting it all together to render a sprite","text":"<p>At this stage you should have the following ready:</p> <ul> <li>The transformation matrix that you will use to apply to all vertices of a mesh.</li> <li>The texture to apply onto the mesh.</li> <li>The mesh to be used to draw after applying the transformation matrix and texture.</li> </ul> <p>The code below shows how to configure the rendering settings and draw a single sprite using the mesh, transform and texture we prepared in the previous sections. Ideally, the code should be placed within the game loop. </p> <pre><code>// Tell the Alpha Engine to set the background to black.\nAEGfxSetBackgroundColor(0.0f, 0.0f, 0.0f);\n\n// Tell the Alpha Engine to get ready to draw something with texture.\nAEGfxSetRenderMode(AE_GFX_RM_TEXTURE);\n\n// Set the the color to multiply to white, so that the sprite can \n// display the full range of colors (default is black).\nAEGfxSetColorToMultiply(1.0f, 1.0f, 1.0f, 1.0f);\n\n// Set the color to add to nothing, so that we don't alter the sprite's color\nAEGfxSetColorToAdd(0.0f, 0.0f, 0.0f, 0.0f);\n\n// Set blend mode to AE_GFX_BM_BLEND, which will allow transparency.\nAEGfxSetBlendMode(AE_GFX_BM_BLEND);\nAEGfxSetTransparency(1.0f);\n\n// Tell Alpha Engine to use the texture stored in pTex\nAEGfxTextureSet(pTex, 0, 0);\n\n// Tell Alpha Engine to use the matrix in 'transform' to apply onto all \n// the vertices of the mesh that we are about to choose to draw in the next line.\nAEGfxSetTransform(transform.m);\n\n// Tell Alpha Engine to draw the mesh with the above settings.\nAEGfxMeshDraw(pMesh, AE_GFX_MDM_TRIANGLES);\n</code></pre> <p>You should see a sprite with the image from PlanetTexture.png drawn on the screen, scaled to 500x500 pixels, rotated by 90 degrees and translated by 100 on the x-axis and 100 on the y-axis like so:</p> <p></p> <p>The completed minimal code to render the sprite above can be found <code>snippets/rendering_a_sprite.png</code>.</p>"},{"location":"rendering_sprites.html#exercise-transformation","title":"Exercise: Transformation","text":"<p>As an exercise, try to do the following:</p> <ul> <li>Draw 3 planets with varying sizes. Let's name the planets A, B and C.<ul> <li>Note that they should use the same mesh. Feel free to have different textures if you want.</li> </ul> </li> <li>Planet A: Stay in the middle of the screen, rotating about itself.</li> <li>Planet B: Rotates around Planet A, while also rotating about itself</li> <li>Planet C: Rotates around Planet B, while also rotating about itself.</li> </ul> <p>The solution for this can be found in <code>snippets\\solar_system.cpp</code>. For more information related to graphics, check out the documentation surrounding the <code>AEGraphics.h</code> file.</p>"},{"location":"rendering_sprites.html#colors-and-color-modification","title":"Colors and Color Modification","text":"<p>For each sprite you choose to render, Alpha Engine has to decide what color to assign each pixel (or fragment) of your sprite.  If we use a texture, Alpha Engine does the heavy lifting of deciding which part of the texture corresponds to which pixel of the sprite. </p> <p>In Alpha Engine, each pixel is represented by 4 color components: Red, Green, Blue and Alpha. Each color component are floating point values that range from 0.0 to 1.0, where 0 means 0% and 1 means 100%. The values representing the Red, Green and Blue components should be straightforward; 1.0 red means 100% red, 0.5 blue mean 50% blue, and so forth.  The value on the Alpha component refers to transparency of the pixel, where 0.0 is not visible and 1.0 is fully opaque.</p> <p>Alpha Engine has support for multiplying and adding values to every color component for each pixel of your sprite before rendering them.</p> <p>Using these functions will enable us to create interesting effects with our sprite. </p> <p>To add colors, we use <code>AEGfxSetColorToAdd()</code>. The concept of adding colors is straightforward; we are simply asking Alpha Engine to add each color component of every pixel of the sprite with the values we set. For example, if we use the code from the &lt;&gt; section and set <code>AEGfxSetColorToAdd()</code> such that we add 100% red:  <pre><code>AEGfxSetBackgroundColor(0.0f, 0.0f, 0.0f);\nAEGfxSetRenderMode(AE_GFX_RM_TEXTURE);\nAEGfxSetColorToMultiply(1.0f, 1.0f, 1.0f, 1.0f);\n\n// Add more red!!\nAEGfxSetColorToAdd(1.0f, 0.0f, 0.0f, 0.0f);\n\nAEGfxSetBlendMode(AE_GFX_BM_BLEND);\nAEGfxSetTransparency(1.0f);\nAEGfxTextureSet(pTex, 0, 0);\nAEGfxSetTransform(transform.m);\nAEGfxMeshDraw(pMesh, AE_GFX_MDM_TRIANGLES);\n</code></pre> <p>The sprite will end up looking like this:</p> <p></p> <p>Tip</p> <p>Note that the transparent part of the sprite remains transparent!</p> <p>Multiplying can be done using <code>AEGfxSetColorToMultiply()</code>.  The concept of multiplying colors is also straightforward; we are asking Alpha Engine to multiply each color component of every pixel of the sprite with the values we set. For example, if we use the code from before and set <code>AEGfxSetColorToAdd()</code> such that we multiply with 200% red: </p> <pre><code>AEGfxSetBackgroundColor(0.0f, 0.0f, 0.0f);\nAEGfxSetRenderMode(AE_GFX_RM_TEXTURE);\n\n// Multiply all red by 200%!!\n// Multiply the rest by 100% so that the colors for \n// the rest of the components remain the same!\nAEGfxSetColorToMultiply(2.0f, 1.0f, 1.0f, 1.0f);\n\nAEGfxSetColorToAdd(0.0f, 0.0f, 0.0f, 0.0f);\nAEGfxSetBlendMode(AE_GFX_BM_BLEND);\nAEGfxSetTransparency(1.0f);\nAEGfxTextureSet(pTex, 0, 0);\nAEGfxSetTransform(transform.m);\nAEGfxMeshDraw(pMesh, AE_GFX_MDM_TRIANGLES);\n</code></pre> <p>The sprite will end up looking like this:</p> <p></p> <p>These are just simple use cases for adding and multiplying colors to your sprites. You are highly encouraged to experiment and come up with unique interesting color effects of your own!</p>"},{"location":"rendering_sprites.html#sprites-without-textures","title":"Sprites without textures","text":"<p>Recall that we created a 1x1 mesh using <code>AEGfxTriAdd</code> and skipped explaining the color parameter.  In this section, we will be talking about that parameter, which can be useful if you don't have a texture to work with.</p> <p>The color parameter for each vertex is represented using 32-bits (or 4 bytes), with each byte representing a color component ranging from 0 to 255.</p> <p>There are many ways to represent colors in this way.  In Alpha Engine, we use the ARGB format, where A means alpha, R means red, G means green and B means blue.  This means that the first byte represents alpha, the second byte represents red, third byte represents green and fourth byte represents blue.</p> <p>The easiest way to visualize this is to use the hexidecimal format, where 0 is <code>00</code> and 255 is <code>FF</code>, like so:</p> <pre><code>u32 color = 0xFFFFFF00;\n//                  ^^ blue\n//                ^^ green\n//              ^^ red\n//           ^^ alpha\n//\n// This means that there is 255 alpha, 255 red, 255 green and 0 blue.\n// This represents an opaque yellow color. \n//\n</code></pre> <p>Each vertex on a mesh can be given a color in this format. Let's set the vertices of our 1x1 mesh with different color:</p> <pre><code>// We inform Alpha Engine that we are going to create a mesh\nAEGfxMeshStart();\n\n// This time, we will look at the 3rd parameter of each line \n// (namely, the 3rd, 8th and 13th parameters).\n// \n//  \n\nAEGfxTriAdd(\n  -0.5f, -0.5f, 0xFFFF0000, 0.0f, 1.0f,  // bottom-left: red\n  0.5f, -0.5f, 0xFF00FF00, 1.0f, 1.0f,   // bottom-right: green\n  -0.5f, 0.5f, 0xFF0000FF, 0.0f, 0.0f);  // top-left: blue\n\nAEGfxTriAdd(\n  0.5f, -0.5f, 0xFF00FF00, 1.0f, 1.0f,   // bottom-right: green\n  0.5f, 0.5f, 0xFFFFFFFF, 1.0f, 0.0f,    // top-right: white\n  -0.5f, 0.5f, 0xFF0000FF, 0.0f, 0.0f);  // top-left: blue\n\n// Saving the mesh (list of triangles) in pMesh\nAEGfxVertexList * pMesh = AEGfxMeshEnd();\n</code></pre> <p>Next, we need to change the render mode to <code>AE_GFX_RM_COLOR</code> before using <code>AEGfxMeshDraw()</code>. This informs Alpha Engine that we are not using the UV coordinates or a texture to draw our mesh, instead using the color values we set for each vertex of our mesh.</p> <pre><code>// Change to AE_GFX_RM_COLOR\n// AEGfxSetRenderMode(AE_GFX_RM_TEXTURE);\nAEGfxSetRenderMode(AE_GFX_RM_COLOR);\n\n//\n// Other settings here...\n//\n\n// Draw the mesh \nAEGfxMeshDraw(pMesh, AE_GFX_MDM_TRIANGLES);\n</code></pre> <p>This will result in something like this:</p> <p></p> <p>Notice that the colors will interpolate across the surface when it goes from one vertex to another!</p>"},{"location":"rendering_text.html","title":"Rendering Text","text":"<p>In Alpha Engine, text rendering is a special component within the Graphics Module. </p> <p>There are 4 functions that is related to text rendering:</p> <ul> <li>AEGfxCreateFont()</li> <li>AEGfxDestroyFont()</li> <li>AEGfxPrint()</li> <li>AEGfxGetPrintSize()</li> </ul>"},{"location":"rendering_text.html#loading-and-unloading-fonts","title":"Loading and unloading fonts","text":"<p>Before we can print text on the screen, we first need to load the font. Do this before the game loop.</p> <pre><code>//\n// Loads a font and prepares it at a font height of 72 pixels.\n//\n// Note that it returns a s8, which is something like a \"handle\"\n// to the font managed by Alpha Engine.\n//\ns8 pFont = AEGfxCreateFont(\"Assets/liberation-mono.ttf\", 72);\n</code></pre> <p>The code above loads a TrueType font file from <code>Assets/liberation-mono.ttf</code> and prepares it to be rendered with a base font-height of 72 pixels.  Internally, Alpha Engine will prepare something like a spritesheet (a.k.a altas) of characters from the font file, which each character a font height of 72 pixels.</p> <p></p> <p>Currently, Alpha Engine will prepare characters from the ASCII value 32 to 127.</p> <p>To unload a font, simply use <code>AEGfxDestroyFont()</code>:</p> <pre><code>// Releases resources used by a font\nAEGfxDestroyFont(pFont);\n</code></pre>"},{"location":"rendering_text.html#printing-text","title":"Printing text","text":"<p>Printing text one the screen is a simple matter of using <code>AEGfxPrint()</code>.  The code below will print white \"Hello World\" text starting from the middle of the window at 72px font height (assume that you loaded the font at 72px font-height).</p> <pre><code>// Put this code between AESysFrameStart() and\n// AESysFrameEnd(), of course! \nAEGfxPrint(pFont,           // font handle given by AEGfxCreateFont()\n           \"Hello World\",   // null-terminated c-string to print\n           0.f,             // x position on normalized coordinates, ranging from -1.f to 1.f \n           0.f,             // y position in normalized coordinates, ranging from -1.f to 1.f \n           1.f,             // how much to scale the text by \n           1.f,             // percentage of red, ranging from 0.f to 1.f \n           1.f,             // percentage of green, ranging from 0.f to 1.f\n           1.f,             // percentage of blue, ranging from 0.f to 1.f \n           1.f);            // percentage of alpha, ranging from 0.f to 1.f\n</code></pre> <p>Warning</p> <p>Be aware that the 3rd and 4th parameters are x and y positions in Normalized Coordinates, which is covered in this section. </p> <p>You might notice that even though we told Alpha Engine to draw from the middle of the screen, the text did not end up aligned nicely in the middle. This is because Alpha Engine draws the text starting from the bottom-left side.</p> <p></p> <p>Although you cannot change the way Alpha Engine renders text, you can use <code>AEGfxGetPrintSize()</code> help simluate text vertical alignment and justification.</p> <p>Below is a snippet of code that will print \"Hello World\" text directly in the middle, with center justification and middle vertical alignment:</p> <pre><code>// Draws text that is neatly aligned to the center of the window.\nconst char* pText = \"Hello World\";\nf32 width, height;\nAEGfxGetPrintSize(pFont, pText, 1.f, &amp;width, &amp;height);\nAEGfxPrint(pFont, pText, -width/2, -height/2, 1, 1, 1, 1, 1);\n</code></pre> <p>More snippets for text rendering can be found at <code>snippets/render_text.cpp</code>.</p> <p>Warning</p> <p>Even though these functions are using the <code>AEGfx</code> prefix, functions that work on <code>AEGfxDrawMesh()</code> like <code>AEGfxSetTransparency()</code> or <code>AEGfxSetTransform()</code> are not guaranteed to work on them.</p>"},{"location":"spritesheets.html","title":"Using Spritesheets","text":"<p>Alpha Engine does not provide a spritesheet animation system, but it does provide enough tools for you to implement one. </p>"},{"location":"spritesheets.html#calculating-the-uv","title":"Calculating the UV","text":"<p>First, you must build a mesh that fits your spritesheet and the animation you want to do.  Let's say we have a spritesheet like the one below:</p> <p></p> <p>In this case, the spritesheet consists of 5 rows and 4 columns sprites.</p> <p>In this example, we will use the same 1x1 mesh that we defined before, but there is a problem: the UV coordinates for each vertex in that mesh encompasses the whole image. This brings us to the next step: we need to calculate the UV coordinates such that it encompasses a sprite in the spritesheet.</p> <p>Tip</p> <p>If you need a refresher on what UV coordinates are, you can refer to &lt;&gt;. <p>Let's calculate the UV such that we target the top-left sprite. Since we have 5 rows and 4 columns in the spritesheet, a sprite's width is 1/4 of the spritesheet's width and its height is 1/5 of the spritesheet's height.   </p> <p>Thus, given that:</p> <ul> <li>\\(v_{tl}\\) is the top left vertex of the mesh.</li> <li>\\(v_{tr}\\) is the top right vertex of the mesh.</li> <li>\\(v_{bl}\\) is the bottom left vertex of the mesh.</li> <li>\\(v_{br}\\) is the bottom left vertex of the mesh.</li> <li>\\(c\\) is the number of columns in your spritesheet. </li> <li>\\(r\\) is the number of rows in your spritesheet. </li> </ul> <p>The formula for calculating the UVs for each vertex of our 1x1 sprite to target the top-left sprite is as follows:</p> \\[  v_{tl} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} \\quad v_{tr} = \\begin{bmatrix} \\frac{1}{c} \\\\ 0 \\end{bmatrix} \\quad v_{bl} = \\begin{bmatrix} 0 \\\\ \\frac{1}{r} \\end{bmatrix} \\quad v_{br} = \\begin{bmatrix} \\frac{1}{c} \\\\ \\frac{1}{r} \\end{bmatrix} \\] <p>which gives us:</p> \\[ v_{tl} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} \\quad v_{tr} = \\begin{bmatrix} \\frac{1}{4} \\\\ 0 \\end{bmatrix} \\quad v_{bl} = \\begin{bmatrix} 0 \\\\ \\frac{1}{5} \\end{bmatrix} \\quad v_{br} = \\begin{bmatrix} \\frac{1}{4} \\\\ \\frac{1}{5} \\end{bmatrix} \\] <p>The code to create the 1x1 mesh with the UV coordinates calculated above is therefore:</p> <pre><code>AEGfxMeshStart();\n\nAEGfxTriAdd(\n  -0.5f, -0.5f, 0xFFFFFFFF, 0.0f, 1/5.f, // bottom left\n  0.5f, -0.5f, 0xFFFFFFFF, 1/4.f, 1/5.f, // bottom right \n  -0.5f, 0.5f, 0xFFFFFFFF, 0.0f, 0.0f);  // top left\n\nAEGfxTriAdd(\n  0.5f, -0.5f, 0xFFFFFFFF, 1/4.f, 1/5.f, // bottom right \n  0.5f, 0.5f, 0xFFFFFFFF, 1/4.f, 0.0f,   // top right\n  -0.5f, 0.5f, 0xFFFFFFFF, 0.0f, 0.0f);  // bottom left\n\nAEGfxVertexList * pMesh = AEGfxMeshEnd();\n</code></pre> <p>Warning</p> <p>This means that for each spritesheet using a different set of UV coordinates, you will need create a seperate mesh! </p>"},{"location":"spritesheets.html#uv-offset","title":"UV Offset","text":"<p>Now that we have a mesh that can the top-left sprite of a spritesheet, how can we target the rest of the sprites? The key lies in <code>AEGfxTextureSet()</code>.  The 2nd and 3rd parameter allows you to pass in an offset that will modify the UV of our vertices. </p> <p>In the case of the spritesheet that we are using in this example, this means that:</p> <ul> <li>The first sprite's offset is \\(x = 0, y = 0\\).</li> <li>The sprite on the first row, second column is \\(x = 1/4, y = 0\\).</li> <li>The sprite on the second row, second column is \\(x= 1/4, y = 1/5\\).</li> <li>And so on.</li> </ul> <p>This gives us the ability to choose which section of the spritesheet we want to render, which subsequently allows us to implement spritesheet animation! The code that performs spritesheet animation for this spritesheet can be found at <code>snippets/spritesheet.cpp</code>.</p>"}]}